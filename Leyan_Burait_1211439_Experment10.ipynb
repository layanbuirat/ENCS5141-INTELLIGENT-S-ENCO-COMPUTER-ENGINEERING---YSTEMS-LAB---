{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 11847535,
          "sourceType": "datasetVersion",
          "datasetId": 7444070
        },
        {
          "sourceId": 726723,
          "sourceType": "datasetVersion",
          "datasetId": 265
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Leyan Burait 1211439 Experment10",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/layanbuirat/ENCS5141-INTELLIGENT-S-ENCO-COMPUTER-ENGINEERING---YSTEMS-LAB---/blob/main/Leyan_Burait_1211439_Experment10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "hDmDIQhFZdjH"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "organizations_stackoverflow_stacksample_path = kagglehub.dataset_download('organizations/stackoverflow/stacksample')\n",
        "leyanbuirat_archive10_zip_path = kagglehub.dataset_download('leyanbuirat/archive10-zip')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "G93Jjr2UZdjK"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leyan Burait\n",
        "1211439\n",
        "                         EXPERIMENT 10"
      ],
      "metadata": {
        "id": "vOnPUgM2ZdjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install whoosh pandas kaggle"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T12:19:15.737392Z",
          "iopub.execute_input": "2025-05-17T12:19:15.737617Z",
          "iopub.status.idle": "2025-05-17T12:19:21.169006Z",
          "shell.execute_reply.started": "2025-05-17T12:19:15.737595Z",
          "shell.execute_reply": "2025-05-17T12:19:21.167997Z"
        },
        "id": "zYR_mxbEZdjM",
        "outputId": "cd297c85-73a8-43fc-cba2-40dc9e2d1dbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting whoosh\n  Downloading Whoosh-2.7.4-py2.py3-none-any.whl.metadata (3.1 kB)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.2)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\nRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\nRequirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.20.3)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\nRequirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\nRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\nRequirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\nRequirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nDownloading Whoosh-2.7.4-py2.py3-none-any.whl (468 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.8/468.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: whoosh\nSuccessfully installed whoosh-2.7.4\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d stackoverflow/stacksample\n",
        "!unzip stacksample.zip"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T12:23:07.193593Z",
          "iopub.execute_input": "2025-05-17T12:23:07.194363Z",
          "iopub.status.idle": "2025-05-17T12:23:08.204306Z",
          "shell.execute_reply.started": "2025-05-17T12:23:07.194306Z",
          "shell.execute_reply": "2025-05-17T12:23:08.203554Z"
        },
        "id": "fBbwOrQaZdjN",
        "outputId": "c9743573-f378-4cad-8405-9627b2909f10"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Traceback (most recent call last):\n  File \"/usr/local/bin/kaggle\", line 10, in <module>\n    sys.exit(main())\n             ^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/kaggle/cli.py\", line 68, in main\n    out = args.func(**command_args)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1734, in dataset_download_cli\n    with self.build_kaggle_client() as kaggle:\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n    username=self.config_values['username'],\n             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\nKeyError: 'username'\nunzip:  cannot find or open stacksample.zip, stacksample.zip.zip or stacksample.zip.ZIP.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pip install whoosh pandas"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T12:35:22.583407Z",
          "iopub.execute_input": "2025-05-17T12:35:22.583731Z",
          "iopub.status.idle": "2025-05-17T12:35:25.968977Z",
          "shell.execute_reply.started": "2025-05-17T12:35:22.583708Z",
          "shell.execute_reply": "2025-05-17T12:35:25.96799Z"
        },
        "id": "GYCZn-l-ZdjO",
        "outputId": "7b81f17a-bee7-43e5-c108-6eaa42d49dfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: whoosh in /usr/local/lib/python3.11/dist-packages (2.7.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "questions=pd.read_csv(\"/kaggle/input/stacksample/Questions.csv\", nrows=20000)\n",
        "questions"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T12:53:08.88603Z",
          "iopub.execute_input": "2025-05-17T12:53:08.886683Z",
          "iopub.status.idle": "2025-05-17T12:53:09.498065Z",
          "shell.execute_reply.started": "2025-05-17T12:53:08.886657Z",
          "shell.execute_reply": "2025-05-17T12:53:09.497411Z"
        },
        "id": "IsuguqqWZdjO",
        "outputId": "36fb76c4-5d85-4a52-ae6c-c3733623657f"
      },
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "            Id  OwnerUserId          CreationDate            ClosedDate  \\\n0           80         26.0  2008-08-01T13:57:07Z                   NaN   \n1           90         58.0  2008-08-01T14:41:24Z  2012-12-26T03:45:49Z   \n2          120         83.0  2008-08-01T15:50:08Z                   NaN   \n3          180    2089740.0  2008-08-01T18:42:19Z                   NaN   \n4          260         91.0  2008-08-01T23:22:08Z                   NaN   \n...        ...          ...                   ...                   ...   \n19995  1114470      82266.0  2009-07-11T19:37:06Z                   NaN   \n19996  1114540    2288585.0  2009-07-11T20:16:06Z                   NaN   \n19997  1114550     131128.0  2009-07-11T20:20:11Z                   NaN   \n19998  1114580      87271.0  2009-07-11T20:35:46Z                   NaN   \n19999  1114600      63472.0  2009-07-11T20:41:50Z                   NaN   \n\n       Score                                              Title  \\\n0         26  SQLStatement.execute() - multiple queries in o...   \n1        144  Good branching and merging tutorials for Torto...   \n2         21                                  ASP.NET Site Maps   \n3         53                 Function for creating color wheels   \n4         49  Adding scripting functionality to .NET applica...   \n...      ...                                                ...   \n19995      0       Trim all chars off file name after first \"_\"   \n19996      7  Xcode question: Quickly jump to a particular s...   \n19997      3  Serializing a generic collection with XMLSeria...   \n19998      1            Using Yahoo Fire Eagle on Grails / Java   \n19999      1  How to share code & xib files between iPhone a...   \n\n                                                    Body  \n0      <p>I've written a database generation script i...  \n1      <p>Are there any really good tutorials explain...  \n2      <p>Has anyone got experience creating <strong>...  \n3      <p>This is something I've pseudo-solved many t...  \n4      <p>I have a little game written in C#. It uses...  \n...                                                  ...  \n19995  <p>I'd like to trim these purchase order file ...  \n19996  <p>What is the quickest way to jump to a parti...  \n19997  <p>Why won't XMLSerializer process my generic ...  \n19998  <p>Has anyone implemented the Yahoo Fire Eagle...  \n19999  <p>I'm in the process of creating an app.  I'd...  \n\n[20000 rows x 7 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>OwnerUserId</th>\n      <th>CreationDate</th>\n      <th>ClosedDate</th>\n      <th>Score</th>\n      <th>Title</th>\n      <th>Body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>80</td>\n      <td>26.0</td>\n      <td>2008-08-01T13:57:07Z</td>\n      <td>NaN</td>\n      <td>26</td>\n      <td>SQLStatement.execute() - multiple queries in o...</td>\n      <td>&lt;p&gt;I've written a database generation script i...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90</td>\n      <td>58.0</td>\n      <td>2008-08-01T14:41:24Z</td>\n      <td>2012-12-26T03:45:49Z</td>\n      <td>144</td>\n      <td>Good branching and merging tutorials for Torto...</td>\n      <td>&lt;p&gt;Are there any really good tutorials explain...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>120</td>\n      <td>83.0</td>\n      <td>2008-08-01T15:50:08Z</td>\n      <td>NaN</td>\n      <td>21</td>\n      <td>ASP.NET Site Maps</td>\n      <td>&lt;p&gt;Has anyone got experience creating &lt;strong&gt;...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>180</td>\n      <td>2089740.0</td>\n      <td>2008-08-01T18:42:19Z</td>\n      <td>NaN</td>\n      <td>53</td>\n      <td>Function for creating color wheels</td>\n      <td>&lt;p&gt;This is something I've pseudo-solved many t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>260</td>\n      <td>91.0</td>\n      <td>2008-08-01T23:22:08Z</td>\n      <td>NaN</td>\n      <td>49</td>\n      <td>Adding scripting functionality to .NET applica...</td>\n      <td>&lt;p&gt;I have a little game written in C#. It uses...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>1114470</td>\n      <td>82266.0</td>\n      <td>2009-07-11T19:37:06Z</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>Trim all chars off file name after first \"_\"</td>\n      <td>&lt;p&gt;I'd like to trim these purchase order file ...</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>1114540</td>\n      <td>2288585.0</td>\n      <td>2009-07-11T20:16:06Z</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>Xcode question: Quickly jump to a particular s...</td>\n      <td>&lt;p&gt;What is the quickest way to jump to a parti...</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>1114550</td>\n      <td>131128.0</td>\n      <td>2009-07-11T20:20:11Z</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Serializing a generic collection with XMLSeria...</td>\n      <td>&lt;p&gt;Why won't XMLSerializer process my generic ...</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>1114580</td>\n      <td>87271.0</td>\n      <td>2009-07-11T20:35:46Z</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>Using Yahoo Fire Eagle on Grails / Java</td>\n      <td>&lt;p&gt;Has anyone implemented the Yahoo Fire Eagle...</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>1114600</td>\n      <td>63472.0</td>\n      <td>2009-07-11T20:41:50Z</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>How to share code &amp; xib files between iPhone a...</td>\n      <td>&lt;p&gt;I'm in the process of creating an app.  I'd...</td>\n    </tr>\n  </tbody>\n</table>\n<p>20000 rows × 7 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from whoosh.fields import Schema, TEXT, ID\n",
        "# Defining index schema\n",
        "schema = Schema(Id=ID(stored=True), Title=TEXT(stored=True),\n",
        "Body=TEXT(stored=True))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:05:04.055248Z",
          "iopub.execute_input": "2025-05-17T13:05:04.055849Z",
          "iopub.status.idle": "2025-05-17T13:05:04.05991Z",
          "shell.execute_reply.started": "2025-05-17T13:05:04.055825Z",
          "shell.execute_reply": "2025-05-17T13:05:04.059097Z"
        },
        "id": "nK_OMFHkZdjO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "index_dir = \"indexdir\"\n",
        "if not os.path.exists(index_dir):\n",
        "  os.mkdir(index_dir)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:07:50.54699Z",
          "iopub.execute_input": "2025-05-17T13:07:50.547558Z",
          "iopub.status.idle": "2025-05-17T13:07:50.551998Z",
          "shell.execute_reply.started": "2025-05-17T13:07:50.547532Z",
          "shell.execute_reply": "2025-05-17T13:07:50.551158Z"
        },
        "id": "BOUWsC2zZdjP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from whoosh.index import create_in\n",
        "from whoosh.index import open_dir\n",
        "\n",
        "# Creating the index\n",
        "ix = create_in(index_dir, schema)\n",
        "# Open the index writer\n",
        "writer = ix.writer()\n",
        "# Iterate over the DataFrame and add documents to the index\n",
        "# we have indexed title, title_body and doc_id\n",
        "for index, row in questions.iterrows():\n",
        "  writer.add_document(Id=str(row['Id']), Title = row['Title'],Body=row['Body'])\n",
        "\n",
        "# Commit and close the writer\n",
        "writer.commit()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:08:04.043564Z",
          "iopub.execute_input": "2025-05-17T13:08:04.043852Z",
          "iopub.status.idle": "2025-05-17T13:08:41.583473Z",
          "shell.execute_reply.started": "2025-05-17T13:08:04.04383Z",
          "shell.execute_reply": "2025-05-17T13:08:41.582755Z"
        },
        "id": "0TxiBgWLZdjP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from whoosh.qparser import QueryParser\n",
        "from whoosh.scoring import TF_IDF\n",
        "from whoosh import scoring\n",
        "\n",
        "# create the query parser\n",
        "qp = QueryParser(\"Title\", schema=schema)\n",
        "# parse the query\n",
        "query_sentence = \"How to install\"\n",
        "query = qp.parse(query_sentence)\n",
        "# create a searcher object\n",
        "searcher_tfidf = ix.searcher(weighting=scoring.TF_IDF())\n",
        "# search documents and store them\n",
        "# we are returing top 3 documents\n",
        "results_tfidf = searcher_tfidf.search(query, limit=3, scored=True)\n",
        "# print the documents\n",
        "for hit in results_tfidf:\n",
        "  print(hit[\"Id\"])\n",
        "  print('\\n')\n",
        "  print(hit[\"Title\"])\n",
        "  print('\\n')\n",
        "  print('------------------\\n')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:09:40.210258Z",
          "iopub.execute_input": "2025-05-17T13:09:40.210593Z",
          "iopub.status.idle": "2025-05-17T13:09:40.240859Z",
          "shell.execute_reply.started": "2025-05-17T13:09:40.210567Z",
          "shell.execute_reply": "2025-05-17T13:09:40.240078Z"
        },
        "id": "UygfK9reZdjP",
        "outputId": "1b1391dd-b3c8-44ca-fd28-0ec066112c92"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "102850\n\n\nHow can I install CPAN modules locally without root access (DynaLoader.pm line 229 error)?\n\n\n------------------\n\n145900\n\n\nHow can I determine that Windows Installer is performing an upgrade rather than a first time install?\n\n\n------------------\n\n351640\n\n\nHow to install Hibernate Tools in Eclipse?\n\n\n------------------\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Test the previous search code with different queries. For each one check how\n",
        "many matched results are returned.\n"
      ],
      "metadata": {
        "id": "vxH5TkVIZdjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from whoosh.qparser import QueryParser\n",
        "from whoosh import scoring\n",
        "\n",
        "# Create the query parser\n",
        "qp = QueryParser(\"Title\", schema=schema)\n",
        "\n",
        "# Define the queries\n",
        "queries = [\"How to install\", \"python\", \"machine learning\"]\n",
        "\n",
        "# Function to perform the search and print results\n",
        "def search_and_print(query_sentence):\n",
        "    # Parse the query\n",
        "    query = qp.parse(query_sentence)\n",
        "\n",
        "    # Create a searcher object\n",
        "    searcher_tfidf = ix.searcher(weighting=scoring.TF_IDF())\n",
        "\n",
        "    # Search documents and store them\n",
        "    results_tfidf = searcher_tfidf.search(query, limit=3, scored=True)\n",
        "\n",
        "    # Print the documents\n",
        "    print(f\"Results for query: '{query_sentence}'\")\n",
        "    print('------------------')\n",
        "    for hit in results_tfidf:\n",
        "        print(f\"Id: {hit['Id']}\")\n",
        "        print(f\"Title: {hit['Title']}\")\n",
        "        print('------------------')\n",
        "\n",
        "# Execute the searches for all queries\n",
        "for query in queries:\n",
        "    search_and_print(query)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:09:09.702246Z",
          "iopub.execute_input": "2025-05-17T13:09:09.703011Z",
          "iopub.status.idle": "2025-05-17T13:09:09.86292Z",
          "shell.execute_reply.started": "2025-05-17T13:09:09.702982Z",
          "shell.execute_reply": "2025-05-17T13:09:09.861982Z"
        },
        "id": "3w-nzzAMZdjQ",
        "outputId": "5adf55ac-961b-4f3c-dc73-1725613518ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Results for query: 'How to install'\n------------------\nId: 102850\nTitle: How can I install CPAN modules locally without root access (DynaLoader.pm line 229 error)?\n------------------\nId: 145900\nTitle: How can I determine that Windows Installer is performing an upgrade rather than a first time install?\n------------------\nId: 351640\nTitle: How to install Hibernate Tools in Eclipse?\n------------------\nResults for query: 'python'\n------------------\nId: 31340\nTitle: How do threads work in Python, and what are common Python-threading specific pitfalls?\n------------------\nId: 868690\nTitle: Good examples of python-memcache (memcached) being used in Python?\n------------------\nId: 1081750\nTitle: PYTHON: Update MULTIPLE COLUMNS with python variables\n------------------\nResults for query: 'machine learning'\n------------------\nId: 949730\nTitle: Machine learning for typos\n------------------\nId: 970060\nTitle: Machine Learning in Game AI\n------------------\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: Repeat the previous search using the BM25F scoring algorithm, which is used\n",
        "in probabilistic retrieval model. Do you see any difference in the returned results?"
      ],
      "metadata": {
        "id": "U4e5rHZqZdjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from whoosh.qparser import QueryParser\n",
        "from whoosh.scoring import TF_IDF\n",
        "from whoosh import scoring\n",
        "\n",
        "# create the query parser\n",
        "qp = QueryParser(\"Title\", schema=schema)\n",
        "\n",
        "# parse the query\n",
        "query_sentence = \"How to install\"\n",
        "query = qp.parse(query_sentence)\n",
        "\n",
        "# create a searcher object\n",
        "searcher_BM25F = ix.searcher(weighting=scoring.BM25F())\n",
        "\n",
        "# search documents and store them\n",
        "# we are returing top 3 documents\n",
        "results_BM25F = searcher_tfidf.search(query, limit=3, scored=True)\n",
        "# print the documents\n",
        "for hit in results_tfidf:\n",
        "      print(hit[\"Id\"])\n",
        "      print('\\n')\n",
        "      print(hit[\"Title\"])\n",
        "      print('\\n')\n",
        "      print('------------------\\n')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:10:00.395207Z",
          "iopub.execute_input": "2025-05-17T13:10:00.395812Z",
          "iopub.status.idle": "2025-05-17T13:10:00.449604Z",
          "shell.execute_reply.started": "2025-05-17T13:10:00.395772Z",
          "shell.execute_reply": "2025-05-17T13:10:00.448765Z"
        },
        "id": "yLITxXrrZdjQ",
        "outputId": "19312804-1fca-4a7c-ea00-ad6a610c3c00"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "102850\n\n\nHow can I install CPAN modules locally without root access (DynaLoader.pm line 229 error)?\n\n\n------------------\n\n145900\n\n\nHow can I determine that Windows Installer is performing an upgrade rather than a first time install?\n\n\n------------------\n\n351640\n\n\nHow to install Hibernate Tools in Eclipse?\n\n\n------------------\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "more_results = results_tfidf[0].more_like_this(\"Title\")\n",
        "for hit in more_results:\n",
        "  print(hit[\"Id\"])\n",
        "  print('\\n')\n",
        "  print(hit[\"Title\"])\n",
        "  print('\\n')\n",
        "  print('------------------\\n')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:10:23.328203Z",
          "iopub.execute_input": "2025-05-17T13:10:23.328513Z",
          "iopub.status.idle": "2025-05-17T13:10:23.336229Z",
          "shell.execute_reply.started": "2025-05-17T13:10:23.328488Z",
          "shell.execute_reply": "2025-05-17T13:10:23.335606Z"
        },
        "id": "YT6RYW0QZdjQ",
        "outputId": "4fdcc1e7-c3f0-4662-daf1-56963652eb95"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "459590\n\n\nWhat is the difference betwen including modules and embedding modules?\n\n\n------------------\n\n423330\n\n\nWhy can't DynaLoader.pm load SSleay.dll for Net::SSLeay and Crypt::SSLeay?\n\n\n------------------\n\n540640\n\n\nHow can I install a CPAN module into a local directory?\n\n\n------------------\n\n172040\n\n\nHow do you develop against OpenID locally\n\n\n------------------\n\n566290\n\n\nSilverlight Development - Service URL while developing locally\n\n\n------------------\n\n766830\n\n\nHow can I locally manage C manuals?\n\n\n------------------\n\n799860\n\n\nUsing Mercurial locally, only with Subversion server\n\n\n------------------\n\n852280\n\n\nUbuntu: \"Could not find rails locally or in a repository\"\n\n\n------------------\n\n78900\n\n\nHow to check for memory leaks in Guile extension modules?\n\n\n------------------\n\n199180\n\n\nIs there any way to get python omnicomplete to work with non-system modules in vim?\n\n\n------------------\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = [keyword for keyword, score\n",
        "\n",
        "in results_tfidf.key_terms(\"Title\", docs=10, numterms=5)]\n",
        "\n",
        "keywords"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:10:57.065851Z",
          "iopub.execute_input": "2025-05-17T13:10:57.066125Z",
          "iopub.status.idle": "2025-05-17T13:10:57.079643Z",
          "shell.execute_reply.started": "2025-05-17T13:10:57.066105Z",
          "shell.execute_reply": "2025-05-17T13:10:57.07882Z"
        },
        "id": "R5rPaF6qZdjQ",
        "outputId": "ca943d91-36d3-461a-e671-4f0bf322807e"
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['install', '229', 'cpan', 'dynaloader.pm', 'locally']"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "queries = {\n",
        "  'q1': \"machine learning\",\n",
        "  'q2':\"AI algorithms\"\n",
        "}\n",
        "relevance = {\n",
        "  'q1' : [\"doc1\", \"doc2\", \"doc3\"],\n",
        "  'q2' : [\"doc1\", \"doc2\", \"doc3\", \"doc4\", \"doc5\"]\n",
        "}\n",
        "documents = {\n",
        "\n",
        "\n",
        "  'doc1': \"Artificial Intelligence (AI) is transforming various industries through automation and advanced algorithms. Machine learning, a subset of AI, enables computers to learn from data and make predictions. Algorithms are at the core of AI systems, guiding decision-making and problem-solving processes. AI-powered systems are increasingly used in healthcare for diagnosis and treatment planning. The ethical implications of AI algorithms, such as bias and fairness, are important considerations in their development.\",\n",
        "  'doc2': \"Deep learning, a branch of machine learning, uses neural networks to process complex data. AI algorithms are capable of analyzing large datasets to extract meaningful insights. Natural Language Processing (NLP) algorithms enable computers to understand and generate human language. AI-driven recommendation algorithms personalize user experiences in e-commerce and content platforms. Ensuring the transparency and accountability of AI algorithms is essential for building trust in AI technologies.\",\n",
        "  'doc3': \"Reinforcement learning algorithms enable AI agents to learn through trial and error interactions with their environment. AI algorithms are used in financial markets for high-frequency trading and risk management. Computer vision algorithms enable machines to interpret and analyze visual information. AI algorithms can enhance cybersecurity by detecting and mitigating cyber threats in real-time. Continuous research and development are essential for advancing AI algorithms and overcoming their limitations.\",\n",
        "  'doc4': \"Evolutionary algorithms, inspired by natural selection, are used to optimize complex systems and processes. AI algorithms play a crucial role in autonomous vehicles for navigation and decision-making. Quantum computing algorithms have the potential to revolutionize AI by solving complex problems exponentially faster AI algorithms are employed in predictive maintenance to anticipate equipment failures and reduce downtime. Ethical guidelines and regulations are needed to govern the development and deployment of AI algorithms.\",\n",
        "  'doc5': \"Genetic algorithms are used to evolve solutions to optimization and search problems inspired by natural selection. AI algorithms enable personalized content recommendations in streaming services and social media platforms. Swarm intelligence algorithms mimic the collective behavior of social insects to solve optimization problems. AI algorithms are used in drug discovery to accelerate the identification of potential treatments. Collaborative efforts are essential for advancing AI algorithms and harnessing their full potential for societal benefit.\"\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:11:19.333002Z",
          "iopub.execute_input": "2025-05-17T13:11:19.333262Z",
          "iopub.status.idle": "2025-05-17T13:11:19.338811Z",
          "shell.execute_reply.started": "2025-05-17T13:11:19.333244Z",
          "shell.execute_reply": "2025-05-17T13:11:19.338012Z"
        },
        "id": "yx67DhG7ZdjQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from whoosh.fields import Schema, TEXT, ID\n",
        "from whoosh.index import create_in\n",
        "from whoosh.index import open_dir\n",
        "# Defining index schema\n",
        "schema = Schema(Id=ID(stored=True), Body=TEXT(stored=True))\n",
        "import os.path\n",
        "index_dir = \"indexdir_toy\"\n",
        "if not os.path.exists(index_dir):\n",
        "  os.mkdir(index_dir)\n",
        "\n",
        "# Creating the index\n",
        "ix = create_in(index_dir, schema)\n",
        "# Open the index writer\n",
        "writer = ix.writer()\n",
        "for doc in documents:\n",
        "  writer.add_document(Id=doc, Body=documents[doc])\n",
        "\n",
        "# Commit and close the writer\n",
        "writer.commit()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:11:34.638034Z",
          "iopub.execute_input": "2025-05-17T13:11:34.638691Z",
          "iopub.status.idle": "2025-05-17T13:11:34.685284Z",
          "shell.execute_reply.started": "2025-05-17T13:11:34.638661Z",
          "shell.execute_reply": "2025-05-17T13:11:34.684579Z"
        },
        "id": "UaC1n_PiZdjR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from whoosh.qparser import QueryParser\n",
        "from whoosh.scoring import TF_IDF\n",
        "from whoosh import scoring\n",
        "# create the query parser\n",
        "qp = QueryParser(\"Body\", schema=schema)\n",
        "# parse the query\n",
        "query_sentence = queries['q1']\n",
        "query = qp.parse(query_sentence)\n",
        "# create a searcher object\n",
        "searcher_tfidf = ix.searcher(weighting=scoring.TF_IDF())\n",
        "# search documents and store them\n",
        "# we are returing top 3 documents\n",
        "results_tfidf = searcher_tfidf.search(query, limit=3, scored=True)\n",
        "\n",
        "\n",
        "# print the documents\n",
        "for hit in results_tfidf:\n",
        "  print(hit[\"Id\"])\n",
        "  print('\\n')\n",
        "  print(hit[\"Body\"])\n",
        "  print('\\n')\n",
        "  print('------------------\\n')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:11:50.705839Z",
          "iopub.execute_input": "2025-05-17T13:11:50.706436Z",
          "iopub.status.idle": "2025-05-17T13:11:50.714665Z",
          "shell.execute_reply.started": "2025-05-17T13:11:50.706415Z",
          "shell.execute_reply": "2025-05-17T13:11:50.713859Z"
        },
        "id": "VQwlFdzuZdjR",
        "outputId": "cb164dc1-efcb-4769-b535-c66651bf15f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "doc2\n\n\nDeep learning, a branch of machine learning, uses neural networks to process complex data. AI algorithms are capable of analyzing large datasets to extract meaningful insights. Natural Language Processing (NLP) algorithms enable computers to understand and generate human language. AI-driven recommendation algorithms personalize user experiences in e-commerce and content platforms. Ensuring the transparency and accountability of AI algorithms is essential for building trust in AI technologies.\n\n\n------------------\n\ndoc1\n\n\nArtificial Intelligence (AI) is transforming various industries through automation and advanced algorithms. Machine learning, a subset of AI, enables computers to learn from data and make predictions. Algorithms are at the core of AI systems, guiding decision-making and problem-solving processes. AI-powered systems are increasingly used in healthcare for diagnosis and treatment planning. The ethical implications of AI algorithms, such as bias and fairness, are important considerations in their development.\n\n\n------------------\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "task 3\n",
        "Task 3: Compute the precision and recall for the retrieved documents in the previous\n",
        "example."
      ],
      "metadata": {
        "id": "DDlRVX_6ZdjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_precision_recall(retrieved_docs, relevant_docs):\n",
        "    retrieved_set = set(retrieved_docs)\n",
        "    relevant_set = set(relevant_docs)\n",
        "    true_positives = retrieved_set.intersection(relevant_set)\n",
        "    precision = len(true_positives) / len(retrieved_set) if retrieved_set else 0\n",
        "    recall = len(true_positives) / len(relevant_set) if relevant_set else 0\n",
        "    return precision, recall\n",
        "\n",
        "# Given query and relevance\n",
        "query_id = 'q1'\n",
        "query_sentence = queries[query_id]\n",
        "relevant_docs = relevance[query_id]\n",
        "\n",
        "# Create the query parser and searcher\n",
        "qp = QueryParser(\"Body\", schema=schema)\n",
        "query = qp.parse(query_sentence)\n",
        "searcher_tfidf = ix.searcher(weighting=scoring.TF_IDF())\n",
        "\n",
        "# Search and retrieve top 3 documents\n",
        "results_tfidf = searcher_tfidf.search(query, limit=3, scored=True)\n",
        "retrieved_docs = [hit[\"Id\"] for hit in results_tfidf]\n",
        "\n",
        "# Compute precision and recall\n",
        "precision, recall = compute_precision_recall(retrieved_docs, relevant_docs)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Query: {query_sentence}\")\n",
        "print(f\"Retrieved Documents: {retrieved_docs}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:13:09.814929Z",
          "iopub.execute_input": "2025-05-17T13:13:09.815492Z",
          "iopub.status.idle": "2025-05-17T13:13:09.827152Z",
          "shell.execute_reply.started": "2025-05-17T13:13:09.815449Z",
          "shell.execute_reply": "2025-05-17T13:13:09.826162Z"
        },
        "id": "9ikdOsncZdjR",
        "outputId": "9347da78-7946-4384-98c9-121267ee359b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Query: machine learning\nRetrieved Documents: ['doc2', 'doc1']\nPrecision: 1.00\nRecall: 0.67\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "task4 Task 4: Modify the last code to test all queries and then report the precision and\n",
        "recall."
      ],
      "metadata": {
        "id": "Bc6nResTZdjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_precision_recall(retrieved_docs, relevant_docs):\n",
        "    retrieved_set = set(retrieved_docs)\n",
        "    relevant_set = set(relevant_docs)\n",
        "    true_positives = retrieved_set.intersection(relevant_set)\n",
        "    precision = len(true_positives) / len(retrieved_set) if retrieved_set else 0\n",
        "    recall = len(true_positives) / len(relevant_set) if relevant_set else 0\n",
        "    return precision, recall\n",
        "\n",
        "# Given query and relevance\n",
        "query_id = 'q1'\n",
        "query_sentence = queries[query_id]\n",
        "relevant_docs = relevance[query_id]\n",
        "\n",
        "# Create the query parser and searcher\n",
        "qp = QueryParser(\"Body\", schema=schema)\n",
        "query = qp.parse(query_sentence)\n",
        "searcher_tfidf = ix.searcher(weighting=scoring.TF_IDF())\n",
        "\n",
        "# Search and retrieve top 3 documents\n",
        "results_tfidf = searcher_tfidf.search(query, limit=3, scored=True)\n",
        "retrieved_docs = [hit[\"Id\"] for hit in results_tfidf]\n",
        "\n",
        "# Compute precision and recall\n",
        "precision, recall = compute_precision_recall(retrieved_docs, relevant_docs)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Query: {query_sentence}\")\n",
        "print(f\"Retrieved Documents: {retrieved_docs}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-17T13:13:47.726111Z",
          "iopub.execute_input": "2025-05-17T13:13:47.726643Z",
          "iopub.status.idle": "2025-05-17T13:13:47.737443Z",
          "shell.execute_reply.started": "2025-05-17T13:13:47.726617Z",
          "shell.execute_reply": "2025-05-17T13:13:47.736578Z"
        },
        "id": "CCxrNyaaZdjR",
        "outputId": "70ae8e92-8159-4c4c-f4f7-f0ff500d19c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Query: machine learning\nRetrieved Documents: ['doc2', 'doc1']\nPrecision: 1.00\nRecall: 0.67\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}